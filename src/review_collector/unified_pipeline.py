import csv
import os
from collections import defaultdict
from datetime import datetime, timedelta

import cosme_crawler
from unified_analyzer import analyze_reviews


# =========================
# ë‚ ì§œ íŒŒì‹± (Amazonìš©)
# =========================
def parse_amazon_date(date_str):
    """
    ì§€ì› í˜•ì‹:
    - 19-Dec-25
    - 2024-12-19
    """
    for fmt in ("%d-%b-%y", "%Y-%m-%d"):
        try:
            return datetime.strptime(date_str, fmt)
        except ValueError:
            pass
    return None


# =========================
# Amazon CSV â†’ ì œí’ˆë³„ + ê¸°ê°„ í•„í„°
# =========================
def load_amazon_reviews_by_product(csv_path, days=None):
    product_reviews = defaultdict(list)

    if days is not None:
        cutoff_date = datetime.today() - timedelta(days=days)
    else:
        cutoff_date = None

    with open(csv_path, mode="r", encoding="utf-8-sig", errors="ignore") as f:
        reader = csv.DictReader(f)
        for row in reader:
            product = row.get("product_name", "").strip()
            review = row.get("review_text", "").strip()
            date_str = row.get("review_date", "").strip()

            if not product or not review or not date_str:
                continue

            review_date = parse_amazon_date(date_str)
            if not review_date:
                continue

            if cutoff_date and review_date < cutoff_date:
                continue

            product_reviews[product].append(review)

    return product_reviews


def run_pipeline():
    print("\n[ë¦¬ë·° ë¶„ì„ ì‹œìŠ¤í…œ]")
    print("1. Amazon (US)")
    print("2. @COSME (JP)")
    site_choice = input("ì‚¬ì´íŠ¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1/2): ").strip()

    print("\n[ê¸°ê°„ ì„¤ì •]")
    print("1. 7ì¼ | 2. 30ì¼ | 3. 90ì¼ | 4. 180ì¼ | 5. ì „ì²´")
    period_choice = input("ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (1~5): ").strip()

    mapping = {"1": 7, "2": 30, "3": 90, "4": 180, "5": None}
    days = mapping.get(period_choice, None)

    # =========================
    # Amazon (CSV ê¸°ë°˜ + ê¸°ê°„ í•„í„°)
    # =========================
    if site_choice == "1":
        print("\nğŸ“¦ Amazon ë¦¬ë·° CSV ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")

        base_dir = os.path.dirname(__file__)
        csv_path = os.path.join(base_dir, "amazon_reviews.csv")

        product_reviews = load_amazon_reviews_by_product(
            csv_path,
            days=days
        )
        source = "Amazon"

    # =========================
    # @COSME
    # =========================
    elif site_choice == "2":
        print("\nğŸ“¦ @COSME ë¦¬ë·° í¬ë¡¤ë§ ì¤‘...")
        product_reviews = cosme_crawler.crawl_laneige_reviews(days=days)
        source = "@COSME"

    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")
        return

    if not product_reviews:
        print("\nâš ï¸ ë¦¬ë·° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nâœ… {source} ë¦¬ë·° ìˆ˜ì§‘ ì™„ë£Œ! ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    for product_name, reviews in product_reviews.items():
        print(f"\nğŸ§¬ ë¶„ì„ ì¤‘: {product_name} ({len(reviews)}ê±´)")
        result = analyze_reviews(product_name, reviews, source)

        print("-" * 50)
        print(result)
        print("-" * 50)


if __name__ == "__main__":
    run_pipeline()
