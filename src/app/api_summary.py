# api_summary.py : ìš”ì•½ ê´€ë ¨ API ë¼ìš°í„°
# ì„œì˜ë‹˜ íŒŒíŠ¸

import sqlite3
import re
from fastapi import APIRouter, HTTPException, Query
from pydantic import BaseModel
from typing import List, Optional
from pathlib import Path

# =========================================================
# [ëª¨ë“ˆ ì„í¬íŠ¸] íŒ€ì›ë¶„ë“¤ì˜ ì½”ë“œ (í¬ë¡¤ëŸ¬ & ë¶„ì„ê¸°) í™œìš©
# =========================================================
try:
    # GPT ë¶„ì„ê¸°
    from src.review_collector.unified_analyzer import analyze_reviews
    # Amazon ë¦¬ë·° ë¡œë”
    from src.review_collector.unified_pipeline import load_amazon_reviews_by_product
    # [NEW] Cosme ì‹¤ì‹œê°„ í¬ë¡¤ëŸ¬
    from src.review_collector.cosme_crawler import crawl_by_id
except ImportError as e:
    print(f"âš ï¸ ëª¨ë“ˆ ì„í¬íŠ¸ ê²½ê³  (ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œ ë¬´ì‹œ ê°€ëŠ¥): {e}")
    pass

# =========================
# 1. ê²½ë¡œ ë° ì„¤ì •
# =========================
BASE_DIR = Path(__file__).resolve().parents[2]
DB_PATH = BASE_DIR / "laneige.db"
# Amazon CSV ê²½ë¡œ (unified_pipeline.pyì™€ ë™ì¼ ìœ„ì¹˜ ê°€ì •)
AMAZON_CSV_PATH = BASE_DIR / "src" / "review_collector" / "amazon_reviews.CSV"

router = APIRouter(
    prefix="/api/summary",
    tags=["Summary Analysis"]
)

# =========================
# 2. ì‘ë‹µ ëª¨ë¸ (í”„ë¡ íŠ¸ì—”ë“œ ê·œê²©)
# =========================
class BasicAnalysis(BaseModel):
    current_ranking: Optional[int]
    rank_change: Optional[int]
    total_reviews: int
    rating: float

class RankingPoint(BaseModel):
    label: str
    rank: Optional[int]

class SentimentData(BaseModel):
    positive: int
    neutral: int
    negative: int

class ProductSummaryResponse(BaseModel):
    product_id: str
    product_name: str
    source: str
    basic_analysis: BasicAnalysis
    ranking_trend: List[RankingPoint]
    keywords: List[str]
    sentiment: SentimentData

# =========================
# 3. GPT ì‘ë‹µ(ì¤„ê¸€) -> JSON ë³€í™˜ í—¬í¼
# =========================
def parse_gpt_response(gpt_text: str):
    """
    unified_analyzer.pyì˜ ê²°ê³¼(ì¤„ê¸€ ë³´ê³ ì„œ)ì—ì„œ í‚¤ì›Œë“œì™€ í¼ì„¼íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    keywords = ["ë¶„ì„ ë°ì´í„° ì—†ìŒ"]
    sentiment = {"pos": 0, "neu": 0, "neg": 0}
    
    if not gpt_text:
        return keywords, sentiment

    try:
        # 1. í‚¤ì›Œë“œ ì¶”ì¶œ (ì˜ˆ: "1. í‚¤ì›Œë“œ: ë³´ìŠµ, í–¥ê¸°...")
        # ì •ê·œì‹: 'í‚¤ì›Œë“œ' ë’¤ì— ì˜¤ëŠ” í…ìŠ¤íŠ¸ ì¡ê¸°
        keyword_match = re.search(r"í‚¤ì›Œë“œ.*?[:\n](.*)", gpt_text)
        if keyword_match:
            raw_keywords = keyword_match.group(1).strip()
            # ì‰¼í‘œë¡œ ë¶„ë¦¬, íŠ¹ìˆ˜ë¬¸ì ì œê±° í›„ ìƒìœ„ 5ê°œ
            keywords = [k.strip().replace("-", "").replace(".", "") for k in raw_keywords.split(",")][:5]

        # 2. ê°ì„± ë¹„ìœ¨ ì¶”ì¶œ (ì˜ˆ: "ê¸ì • 80%, ì¤‘ë¦½ 10%, ë¶€ì • 10%")
        # % ì•ì˜ ìˆ«ìë¥¼ ì°¾ì•„ì„œ ìˆœì„œëŒ€ë¡œ ë§¤í•‘
        numbers = re.findall(r"(\d+)%", gpt_text)
        if len(numbers) >= 3:
            sentiment["pos"] = int(numbers[0])
            sentiment["neu"] = int(numbers[1])
            sentiment["neg"] = int(numbers[2])
    
    except Exception as e:
        print(f"GPT íŒŒì‹± ì—ëŸ¬: {e}")
    
    return keywords, sentiment

# =========================
# 4. API ì—”ë“œí¬ì¸íŠ¸
# =========================
@router.get("/{product_id}", response_model=ProductSummaryResponse)
async def get_product_summary(
    product_id: str, 
    source: str = Query(..., description="amazon ë˜ëŠ” cosme")
):
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    try:
        product_name = ""
        current_rank = 0
        rating = 0.0
        total_reviews = 0
        ranking_trend = []
        
        # -------------------------------------------------
        # [Step 1] DBì—ì„œ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ (Amazon / Cosme ê³µí†µ)
        # -------------------------------------------------
        if source.lower() == 'amazon':
            cursor.execute("SELECT * FROM amazon WHERE productcode = ?", (product_id,))
            rows = cursor.fetchall()
            if not rows: raise HTTPException(status_code=404, detail="Product not found in Amazon DB")
            
            latest = rows[-1]
            product_name = latest['productname']
            current_rank = latest['rank']
            rating = latest['rating']
            
            for i, row in enumerate(rows):
                label = row['crawldate'][:10] if 'crawldate' in row.keys() else f"Week {i+1}"
                ranking_trend.append(RankingPoint(label=label, rank=row['rank']))

        elif source.lower() == 'cosme':
            cursor.execute("SELECT * FROM cosme WHERE product_id = ?", (product_id,))
            rows = cursor.fetchall()
            if not rows: raise HTTPException(status_code=404, detail="Product not found in Cosme DB")
            
            latest = rows[-1]
            # DBì— product_name ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ë¸Œëœë“œëª…ìœ¼ë¡œ ëŒ€ì²´
            product_name = latest['product_name'] if 'product_name' in latest.keys() else f"{latest['brand_name']} Item"
            current_rank = int(latest['global_rank']) if latest['global_rank'] else 0
            rating = latest['rating_score']
            
            for i, row in enumerate(rows):
                label = row['date'] if 'date' in row.keys() else f"Week {i+1}"
                val = int(row['global_rank']) if row['global_rank'] else 0
                ranking_trend.append(RankingPoint(label=label, rank=val))

        # -------------------------------------------------
        # [Step 2] ë¦¬ë·° ë°ì´í„° ìˆ˜ì§‘ & ë¶„ì„ (Sourceë³„ ë¶„ê¸°)
        # -------------------------------------------------
        reviews = []
        
        # Case A: Amazon (CSV íŒŒì¼ ë¡œë“œ)
        if source.lower() == 'amazon':
            target_key = product_name.lower().replace(" ", "")
            # íŒ€ì› ì½”ë“œë¥¼ í™œìš©í•´ CSVì—ì„œ ë¡œë“œ
            reviews = load_amazon_reviews_by_product(str(AMAZON_CSV_PATH), target_key)
            
            # ì •í™•í•œ ë§¤ì¹­ì´ ì—†ìœ¼ë©´ 'Laneige' í‚¤ì›Œë“œë¡œ ì¬ê²€ìƒ‰ (Fallback)
            if not reviews and "laneige" in product_name.lower():
                reviews = load_amazon_reviews_by_product(str(AMAZON_CSV_PATH), "laneige")

        # Case B: Cosme (ì‹¤ì‹œê°„ í¬ë¡¤ë§)
        elif source.lower() == 'cosme':
            print(f"ğŸš€ [Cosme] ID {product_id} ì‹¤ì‹œê°„ í¬ë¡¤ë§ ì‹œì‘...")
            try:
                # ì†ë„ë¥¼ ìœ„í•´ max_pages=1 (ì•½ 20ê°œ ë¦¬ë·°)ë¡œ ì œí•œ
                reviews = crawl_by_id(product_id, max_pages=1)
                print(f"âœ… [Cosme] ë¦¬ë·° {len(reviews)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ [Cosme] í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
                reviews = []

        # -------------------------------------------------
        # [Step 3] GPT ë¶„ì„ ì‹¤í–‰
        # -------------------------------------------------
        keywords = ["ë¦¬ë·° ë¶€ì¡±"]
        sentiment_dict = {"pos": 0, "neu": 0, "neg": 0}

        if reviews:
            # ë¶„ì„ ì‹¤í–‰ (Unified Analyzer í™œìš©)
            gpt_report = analyze_reviews(product_name, reviews, source)
            
            # ê²°ê³¼ íŒŒì‹±
            keywords, sentiment_dict = parse_gpt_response(gpt_report)
            
            # ì‹¤ì œ ë¦¬ë·° ê°œìˆ˜ ì—…ë°ì´íŠ¸
            total_reviews = len(reviews)
        else:
            # ë¦¬ë·°ê°€ ì—†ì„ ê²½ìš° DBì— ìˆëŠ” review_count ì‚¬ìš© (ìˆë‹¤ë©´)
            if source.lower() == 'amazon':
                total_reviews = latest['reviewcount'] if 'reviewcount' in latest.keys() else 0
            elif source.lower() == 'cosme':
                total_reviews = latest['review_count'] if 'review_count' in latest.keys() else 0

        # -------------------------------------------------
        # [Step 4] ìµœì¢… ë°˜í™˜
        # -------------------------------------------------
        return ProductSummaryResponse(
            product_id=product_id,
            product_name=product_name,
            source=source,
            basic_analysis=BasicAnalysis(
                current_ranking=current_rank,
                rank_change=0, # ê³¼ê±° ë°ì´í„°ê°€ ì¶©ë¶„í•˜ë©´ ê³„ì‚° ê°€ëŠ¥
                total_reviews=total_reviews,
                rating=rating
            ),
            ranking_trend=ranking_trend,
            keywords=keywords,
            sentiment=SentimentData(
                positive=sentiment_dict['pos'],
                neutral=sentiment_dict['neu'],
                negative=sentiment_dict['neg']
            )
        )

    finally:
        conn.close()